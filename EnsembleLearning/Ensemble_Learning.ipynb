{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble_Learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFPWSNyb6KrkdBdsNDWN1U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/besherh/Machine-Learning-Course/blob/master/EnsembleLearning/Ensemble_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nazfNKxhJd4A"
      },
      "source": [
        "#A case study\n",
        "The dataset you are going to be using for this case study is popularly known as the Wisconsin Breast Cancer dataset. The task related to it is Classification.\n",
        "\n",
        "The dataset contains a total number of 10 features labeled in either benign or malignant classes. The features have 699 instances out of which 16 feature values are missing. The dataset only contains numeric values.\n",
        "\n",
        "The dataset can be downloaded from our Github page.\n",
        "https://github.com/besherh/Machine-Learning-Course/blob/master/EnsembleLearning/datasets/breast-cancer.csv\n",
        "\n",
        "You will implement the Ensembles using the mighty scikit-learn library.\n",
        "\n",
        "Let's first import all the Python dependencies you will be needing for this case study.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjd7oZoxI-zp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gfa_mA4KwP5"
      },
      "source": [
        "Let's load the dataset in a DataFrame object.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "4nPC7w1OKwrD",
        "outputId": "71e246b3-424d-4d96-c6ea-d0ed55c7d8a2"
      },
      "source": [
        "data = pd.read_csv('breast-cancer.csv')\n",
        "data.head()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample code number</th>\n",
              "      <th>Clump Thickness</th>\n",
              "      <th>Uniformity of Cell Size</th>\n",
              "      <th>Uniformity of Cell Shape</th>\n",
              "      <th>Marginal Adhesion</th>\n",
              "      <th>Single Epithelial Cell Size</th>\n",
              "      <th>Bare Nuclei</th>\n",
              "      <th>Bland Chromatin</th>\n",
              "      <th>Normal Nucleoli</th>\n",
              "      <th>Mitoses</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000025</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002945</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015425</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1016277</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1017023</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sample code number  Clump Thickness  ...  Mitoses  Class\n",
              "0             1000025                5  ...        1      2\n",
              "1             1002945                5  ...        1      2\n",
              "2             1015425                3  ...        1      2\n",
              "3             1016277                6  ...        1      2\n",
              "4             1017023                4  ...        1      2\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBRkbFjXK48X"
      },
      "source": [
        "The column \"Sample code number\" is just an indicator and it's of no use in the modeling. So, let's drop it:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "1CmDOwbMK5uP",
        "outputId": "ed9ec52e-373f-4c95-f55c-0b685853effe"
      },
      "source": [
        "data.drop(['Sample code number'],axis = 1, inplace = True)\n",
        "data.head()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clump Thickness</th>\n",
              "      <th>Uniformity of Cell Size</th>\n",
              "      <th>Uniformity of Cell Shape</th>\n",
              "      <th>Marginal Adhesion</th>\n",
              "      <th>Single Epithelial Cell Size</th>\n",
              "      <th>Bare Nuclei</th>\n",
              "      <th>Bland Chromatin</th>\n",
              "      <th>Normal Nucleoli</th>\n",
              "      <th>Mitoses</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Clump Thickness  Uniformity of Cell Size  ...  Mitoses  Class\n",
              "0                5                        1  ...        1      2\n",
              "1                5                        4  ...        1      2\n",
              "2                3                        1  ...        1      2\n",
              "3                6                        8  ...        1      2\n",
              "4                4                        1  ...        1      2\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg9WA9Q1K-pv"
      },
      "source": [
        "You can see that the column is dropped now. Let's get some statistics about the data using Panda's describe() and info() functions:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Y7RWn5zrK__p",
        "outputId": "1401be8c-8c37-40f8-d5e7-a524e86158a1"
      },
      "source": [
        "data.describe()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clump Thickness</th>\n",
              "      <th>Uniformity of Cell Size</th>\n",
              "      <th>Uniformity of Cell Shape</th>\n",
              "      <th>Marginal Adhesion</th>\n",
              "      <th>Single Epithelial Cell Size</th>\n",
              "      <th>Bland Chromatin</th>\n",
              "      <th>Normal Nucleoli</th>\n",
              "      <th>Mitoses</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>699.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.417740</td>\n",
              "      <td>3.134478</td>\n",
              "      <td>3.207439</td>\n",
              "      <td>2.806867</td>\n",
              "      <td>3.216023</td>\n",
              "      <td>3.437768</td>\n",
              "      <td>2.866953</td>\n",
              "      <td>1.589413</td>\n",
              "      <td>2.689557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.815741</td>\n",
              "      <td>3.051459</td>\n",
              "      <td>2.971913</td>\n",
              "      <td>2.855379</td>\n",
              "      <td>2.214300</td>\n",
              "      <td>2.438364</td>\n",
              "      <td>3.053634</td>\n",
              "      <td>1.715078</td>\n",
              "      <td>0.951273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Clump Thickness  Uniformity of Cell Size  ...     Mitoses       Class\n",
              "count       699.000000               699.000000  ...  699.000000  699.000000\n",
              "mean          4.417740                 3.134478  ...    1.589413    2.689557\n",
              "std           2.815741                 3.051459  ...    1.715078    0.951273\n",
              "min           1.000000                 1.000000  ...    1.000000    2.000000\n",
              "25%           2.000000                 1.000000  ...    1.000000    2.000000\n",
              "50%           4.000000                 1.000000  ...    1.000000    2.000000\n",
              "75%           6.000000                 5.000000  ...    1.000000    4.000000\n",
              "max          10.000000                10.000000  ...   10.000000    4.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9zmTv5kLCPz",
        "outputId": "71e5ee41-056b-4876-be37-2c650df7fc0c"
      },
      "source": [
        "data.info()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 699 entries, 0 to 698\n",
            "Data columns (total 10 columns):\n",
            " #   Column                       Non-Null Count  Dtype \n",
            "---  ------                       --------------  ----- \n",
            " 0   Clump Thickness              699 non-null    int64 \n",
            " 1   Uniformity of Cell Size      699 non-null    int64 \n",
            " 2   Uniformity of Cell Shape     699 non-null    int64 \n",
            " 3   Marginal Adhesion            699 non-null    int64 \n",
            " 4   Single Epithelial Cell Size  699 non-null    int64 \n",
            " 5   Bare Nuclei                  699 non-null    object\n",
            " 6   Bland Chromatin              699 non-null    int64 \n",
            " 7   Normal Nucleoli              699 non-null    int64 \n",
            " 8   Mitoses                      699 non-null    int64 \n",
            " 9   Class                        699 non-null    int64 \n",
            "dtypes: int64(9), object(1)\n",
            "memory usage: 54.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Ezn0jHLE6j"
      },
      "source": [
        "As mentioned earlier, the dataset contains missing values. The column named \"Bare Nuclei\" contains them. Let's verify.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZBV2LxZLGYb",
        "outputId": "a7fadb43-20a6-4a20-ab52-9ae5141d533b"
      },
      "source": [
        "data['Bare Nuclei'].to_numpy()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', '10', '2', '4', '1', '10', '10', '1', '1', '1', '1', '1', '3',\n",
              "       '3', '9', '1', '1', '1', '10', '1', '10', '7', '1', '?', '1', '7',\n",
              "       '1', '1', '1', '1', '1', '1', '5', '1', '1', '1', '1', '1', '10',\n",
              "       '7', '?', '3', '10', '1', '1', '1', '9', '1', '1', '8', '3', '4',\n",
              "       '5', '8', '8', '5', '6', '1', '10', '2', '3', '2', '8', '2', '1',\n",
              "       '2', '1', '10', '9', '1', '1', '2', '1', '10', '4', '2', '1', '1',\n",
              "       '3', '1', '1', '1', '1', '2', '9', '4', '8', '10', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '6', '10', '5', '5', '1', '3',\n",
              "       '1', '3', '10', '10', '1', '9', '2', '9', '10', '8', '3', '5', '2',\n",
              "       '10', '3', '2', '1', '2', '10', '10', '7', '1', '10', '1', '10',\n",
              "       '1', '1', '1', '10', '1', '1', '2', '1', '1', '1', '?', '1', '1',\n",
              "       '5', '5', '1', '?', '8', '2', '1', '10', '1', '10', '5', '3', '1',\n",
              "       '10', '1', '1', '?', '10', '10', '1', '1', '3', '?', '2', '10',\n",
              "       '1', '1', '1', '1', '1', '1', '10', '10', '10', '1', '1', '1',\n",
              "       '10', '1', '1', '1', '10', '10', '1', '8', '10', '8', '1', '8',\n",
              "       '10', '1', '1', '1', '1', '7', '1', '1', '1', '10', '10', '1', '1',\n",
              "       '1', '10', '5', '1', '1', '1', '10', '8', '1', '10', '10', '5',\n",
              "       '1', '1', '4', '1', '1', '10', '5', '8', '10', '1', '10', '5', '1',\n",
              "       '10', '7', '8', '1', '10', '1', '?', '10', '2', '9', '10', '2',\n",
              "       '1', '1', '5', '1', '2', '10', '9', '1', '?', '1', '10', '10',\n",
              "       '10', '8', '10', '1', '1', '1', '8', '10', '10', '10', '10', '3',\n",
              "       '1', '10', '10', '4', '1', '10', '1', '10', '4', '1', '?', '1',\n",
              "       '1', '1', '7', '1', '1', '10', '10', '10', '10', '10', '1', '5',\n",
              "       '10', '1', '1', '?', '10', '?', '10', '5', '?', '1', '10', '4',\n",
              "       '1', '10', '1', '10', '10', '1', '1', '3', '5', '1', '1', '1', '1',\n",
              "       '1', '?', '10', '8', '1', '5', '10', '?', '1', '10', '1', '1',\n",
              "       '10', '1', '4', '10', '8', '1', '1', '10', '10', '1', '10', '1',\n",
              "       '1', '10', '10', '1', '1', '1', '10', '1', '1', '1', '1', '8', '1',\n",
              "       '1', '3', '10', '1', '1', '3', '10', '4', '7', '10', '10', '3',\n",
              "       '3', '1', '1', '10', '10', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '10', '1', '1', '1', '1', '10', '1', '1',\n",
              "       '2', '1', '10', '1', '1', '1', '1', '1', '1', '1', '1', '9', '1',\n",
              "       '1', '4', '1', '1', '1', '1', '2', '1', '1', '?', '4', '1', '10',\n",
              "       '3', '10', '1', '2', '1', '3', '10', '1', '1', '1', '10', '1', '2',\n",
              "       '1', '1', '1', '1', '1', '1', '8', '10', '1', '1', '1', '1', '10',\n",
              "       '4', '3', '2', '1', '1', '1', '1', '1', '10', '1', '1', '1', '10',\n",
              "       '1', '6', '10', '3', '1', '1', '1', '5', '1', '1', '1', '4', '10',\n",
              "       '10', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '10',\n",
              "       '1', '1', '5', '10', '1', '3', '1', '10', '3', '4', '1', '10', '1',\n",
              "       '10', '5', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '5', '4', '1', '1', '1', '1', '1', '1', '10', '10', '1', '1', '1',\n",
              "       '10', '1', '1', '5', '10', '1', '1', '1', '1', '1', '1', '10', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1',\n",
              "       '1', '10', '1', '1', '5', '1', '1', '1', '5', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '10', '1', '3', '10', '5', '10',\n",
              "       '10', '1', '1', '2', '1', '1', '1', '1', '1', '1', '10', '10', '1',\n",
              "       '1', '1', '10', '1', '3', '1', '1', '10', '10', '1', '10', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '10', '8', '1', '1', '10',\n",
              "       '1', '10', '2', '10', '1', '1', '1', '1', '?', '1', '1', '1', '2',\n",
              "       '1', '1', '1', '4', '6', '5', '1', '1', '1', '1', '1', '3', '1',\n",
              "       '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '2', '1', '4', '1', '1', '1', '1', '1', '1', '1', '10', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '5', '8', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '10', '10', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '5', '1', '1', '2', '1', '3', '4', '5'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgzTIHjqMaxg"
      },
      "source": [
        "You can spot some \"?\"s in it, right? Well, these are your missing values, and you will be imputing them with Mean Imputation. But first, you will replace those \"?\"s with 0's.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_lqEHCUMb_v"
      },
      "source": [
        "data.replace('?',0, inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1tmZupfMfRO",
        "outputId": "0c6bf957-f903-4066-837c-7d6f99be2334"
      },
      "source": [
        "data['Bare Nuclei'].to_numpy()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', '10', '2', '4', '1', '10', '10', '1', '1', '1', '1', '1', '3',\n",
              "       '3', '9', '1', '1', '1', '10', '1', '10', '7', '1', 0, '1', '7',\n",
              "       '1', '1', '1', '1', '1', '1', '5', '1', '1', '1', '1', '1', '10',\n",
              "       '7', 0, '3', '10', '1', '1', '1', '9', '1', '1', '8', '3', '4',\n",
              "       '5', '8', '8', '5', '6', '1', '10', '2', '3', '2', '8', '2', '1',\n",
              "       '2', '1', '10', '9', '1', '1', '2', '1', '10', '4', '2', '1', '1',\n",
              "       '3', '1', '1', '1', '1', '2', '9', '4', '8', '10', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '6', '10', '5', '5', '1', '3',\n",
              "       '1', '3', '10', '10', '1', '9', '2', '9', '10', '8', '3', '5', '2',\n",
              "       '10', '3', '2', '1', '2', '10', '10', '7', '1', '10', '1', '10',\n",
              "       '1', '1', '1', '10', '1', '1', '2', '1', '1', '1', 0, '1', '1',\n",
              "       '5', '5', '1', 0, '8', '2', '1', '10', '1', '10', '5', '3', '1',\n",
              "       '10', '1', '1', 0, '10', '10', '1', '1', '3', 0, '2', '10', '1',\n",
              "       '1', '1', '1', '1', '1', '10', '10', '10', '1', '1', '1', '10',\n",
              "       '1', '1', '1', '10', '10', '1', '8', '10', '8', '1', '8', '10',\n",
              "       '1', '1', '1', '1', '7', '1', '1', '1', '10', '10', '1', '1', '1',\n",
              "       '10', '5', '1', '1', '1', '10', '8', '1', '10', '10', '5', '1',\n",
              "       '1', '4', '1', '1', '10', '5', '8', '10', '1', '10', '5', '1',\n",
              "       '10', '7', '8', '1', '10', '1', 0, '10', '2', '9', '10', '2', '1',\n",
              "       '1', '5', '1', '2', '10', '9', '1', 0, '1', '10', '10', '10', '8',\n",
              "       '10', '1', '1', '1', '8', '10', '10', '10', '10', '3', '1', '10',\n",
              "       '10', '4', '1', '10', '1', '10', '4', '1', 0, '1', '1', '1', '7',\n",
              "       '1', '1', '10', '10', '10', '10', '10', '1', '5', '10', '1', '1',\n",
              "       0, '10', 0, '10', '5', 0, '1', '10', '4', '1', '10', '1', '10',\n",
              "       '10', '1', '1', '3', '5', '1', '1', '1', '1', '1', 0, '10', '8',\n",
              "       '1', '5', '10', 0, '1', '10', '1', '1', '10', '1', '4', '10', '8',\n",
              "       '1', '1', '10', '10', '1', '10', '1', '1', '10', '10', '1', '1',\n",
              "       '1', '10', '1', '1', '1', '1', '8', '1', '1', '3', '10', '1', '1',\n",
              "       '3', '10', '4', '7', '10', '10', '3', '3', '1', '1', '10', '10',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '10', '1', '1', '1', '1', '10', '1', '1', '2', '1', '10', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '9', '1', '1', '4', '1', '1', '1',\n",
              "       '1', '2', '1', '1', 0, '4', '1', '10', '3', '10', '1', '2', '1',\n",
              "       '3', '10', '1', '1', '1', '10', '1', '2', '1', '1', '1', '1', '1',\n",
              "       '1', '8', '10', '1', '1', '1', '1', '10', '4', '3', '2', '1', '1',\n",
              "       '1', '1', '1', '10', '1', '1', '1', '10', '1', '6', '10', '3', '1',\n",
              "       '1', '1', '5', '1', '1', '1', '4', '10', '10', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '10', '1', '1', '5', '10', '1',\n",
              "       '3', '1', '10', '3', '4', '1', '10', '1', '10', '5', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '5', '4', '1', '1', '1',\n",
              "       '1', '1', '1', '10', '10', '1', '1', '1', '10', '1', '1', '5',\n",
              "       '10', '1', '1', '1', '1', '1', '1', '10', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '10', '1', '1',\n",
              "       '5', '1', '1', '1', '5', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '10', '1', '3', '10', '5', '10', '10', '1', '1',\n",
              "       '2', '1', '1', '1', '1', '1', '1', '10', '10', '1', '1', '1', '10',\n",
              "       '1', '3', '1', '1', '10', '10', '1', '10', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '10', '8', '1', '1', '10', '1', '10', '2',\n",
              "       '10', '1', '1', '1', '1', 0, '1', '1', '1', '2', '1', '1', '1',\n",
              "       '4', '6', '5', '1', '1', '1', '1', '1', '3', '1', '1', '1', '2',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '4',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '10', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '5', '8', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '10', '10', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '5', '1', '1', '2', '1', '3', '4', '5'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtYcT5wNMkbr"
      },
      "source": [
        "The \"?\"s are replaced with 0's now. Let's do the missing value treatment now.\n",
        "\n",
        "\n",
        "For various reasons, many real world datasets contain missing values, often encoded as blanks, NaNs or other placeholders. Such datasets however are incompatible with scikit-learn estimators which assume that all values in an array are numerical, and that all have and hold meaning. A basic strategy to use incomplete datasets is to discard entire rows and/or columns containing missing values. However, this comes at the price of losing data which may be valuable (even though incomplete). A better strategy is to impute the missing values, i.e., to infer them from the known part of the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUK_rZuNMrGz"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Convert the DataFrame object into NumPy array otherwise you will not be able to impute\n",
        "values = data.values\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "# Now impute it\n",
        "imputedData = imputer.fit_transform(values)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elChP_JqN2hj"
      },
      "source": [
        "Now if you take a look at the dataset itself, you will see that all the ranges of the features of the dataset are not the same. This may cause a problem. A small change in a feature might not affect the other. To address this problem, you will normalize the ranges of the features to a uniform range, in this case, 0 - 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgAR3cEzN36a"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "normalizedData = scaler.fit_transform(imputedData)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY2jsmGqOBAp"
      },
      "source": [
        "You have performed all the preprocessing that was required in order to perform your Ensembling experiments.\n",
        "\n",
        "You will start with Bagging based Ensembling. In this case, you will use a Bagged Decision Tree.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7jGU_8QODYR"
      },
      "source": [
        "# Bagged Decision Trees for Classification - necessary dependencies\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi7VU2okOFPn"
      },
      "source": [
        "You have imported the dependencies for the Bagged Decision Trees.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaV0pRK1OHNT"
      },
      "source": [
        "# Segregate the features from the labels\n",
        "X = normalizedData[:,0:9]\n",
        "Y = normalizedData[:,9]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPI2rWScOg1H"
      },
      "source": [
        "Remember, in bagging we need to divide the data set into diffrenet subsets. We are going apply this using a new technique called k-Fold Cross-Validation\n",
        "#k-Fold Cross-Validation\n",
        "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
        "\n",
        "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.\n",
        "\n",
        "Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.\n",
        "\n",
        "The general procedure is as follows:\n",
        "\n",
        "Shuffle the dataset randomly.\n",
        "\n",
        "\n",
        "Split the dataset into k groups.\n",
        "\n",
        "For each unique group:\n",
        "\n",
        "*   Take the group as a hold out or test data set\n",
        "*   Take the remaining groups as a training data set\n",
        "*   Fit a model on the training set and evaluate it on the test set\n",
        "*   Retain the evaluation score and discard the model    \n",
        "   \n",
        "Summarize the skill of the model using the sample of model evaluation scores\n",
        "\n",
        "\n",
        "To learn more about k-flod refer to this link :\n",
        "https://machinelearningmastery.com/k-fold-cross-validation/ \n",
        "or this:\n",
        "\n",
        "https://www.youtube.com/watch?v=CRqLeHpACVI\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV6E8J8cOhNk",
        "outputId": "f4f2f13e-d72f-4388-860a-5708f030e4a6"
      },
      "source": [
        "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
        "cart = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=7)\n",
        "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9585714285714285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNy7d6LoRD10"
      },
      "source": [
        "Let's see what you did in the above cell.\n",
        "\n",
        "First, you initialized a 10-fold cross-validation fold. After that, you instantiated a Decision Tree Classifier with 100 trees and wrapped it in a Bagging-based Ensemble. Then you evaluated your model.\n",
        "\n",
        "You model performed pretty well. It yielded an accuracy of 95.71%.\n",
        "\n",
        "Brilliant! Let's implement the other ones.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0klmeyrlRHoI",
        "outputId": "62cd0178-79c5-4fa2-ffad-97b4ad5833b0"
      },
      "source": [
        "# AdaBoost Classification\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "seed = 7\n",
        "num_trees = 70\n",
        "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
        "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9557142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt_0z4jVRLkP"
      },
      "source": [
        "In this case, you did an AdaBoost classification (with 70 trees) which is based on Boosting type of Ensembling. The model gave you an accuracy of 95.57% for 10-fold cross-validation.\n",
        "\n",
        "Finally, it's time for you to implement the Voting-based Ensemble technique.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWyKP2PrRMQT",
        "outputId": "1a6ec63e-ae5f-4b1a-b99b-e085b04c8d73"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "# create the sub models\n",
        "estimators = []\n",
        "model1 = LogisticRegression()\n",
        "estimators.append(('logistic', model1))\n",
        "model2 = DecisionTreeClassifier()\n",
        "estimators.append(('cart', model2))\n",
        "model3 = SVC()\n",
        "estimators.append(('svm', model3))\n",
        "# create the ensemble model\n",
        "ensemble = VotingClassifier(estimators)\n",
        "results = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9571221532091098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdWZ2YxjReO0"
      },
      "source": [
        "Take it further:\n",
        "Try other Boosting-based Ensemble techniques viz. Gradient Boosting, XGBoost, etc.\n",
        "Play with the different parameter settings that scikit-learn offers in Ensembles and then try to find why a particular setting performed well. This will make your understanding even stronger. link\n",
        "Try Ensemble learning on a variety of datasets to understand where you should and where you should not apply Ensemble learning. For finding datasets Kaggle, UCI Repository, etc. are good places to search.\n"
      ]
    }
  ]
}